{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 02_silver_notebook_gswin\n",
                "\n",
                "**Purpose**: Migrate GSwin Data container from Alteryx ETL Process V3 to Fabric PySpark.\n",
                "\n",
                "**Source**: `APAC_CRM_Analytics_LH.src_gswin_crb` (Bronze)\n",
                "\n",
                "**Output**: `APAC_Reporting_LH.clean_gswin_chloe` (Silver)\n",
                "\n",
                "**Reference Tables** (all in `APAC_CRM_Analytics_LH`):\n",
                "- `ref_Chloe_gswin_product_mapping` — Product / LOB mapping\n",
                "- `ref_Chloe_insurer_mapping` — Insurer mapping (shared)\n",
                "- `ref_Chloe_gswin_insurer_mapping` — Insurer country mapping\n",
                "\n",
                "**Alteryx Tool Mapping**:\n",
                "| Cell | Alteryx Tools |\n",
                "| :--- | :--- |\n",
                "| Cell 2 | Input (171), Select (173), Filter (174) |\n",
                "| Cell 3 | Formula (172) — 13 expressions |\n",
                "| Cell 4 | N/A — single stream, no union |\n",
                "| Cell 5 | Product Join (175/176), Insurer Join (177), Insurer Country Join (178/179), Final Select (180) |\n",
                "| Cell 6 | Output to Silver |"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "outputs": [],
            "execution_count": null,
            "source": [
                "# =============================================================================\n",
                "# Cell 1: Setup & Configuration\n",
                "# =============================================================================\n",
                "from pyspark.sql import functions as F\n",
                "from pyspark.sql.types import StringType, DoubleType, DateType, IntegerType, LongType, FloatType, DecimalType\n",
                "from pyspark.sql.utils import AnalysisException\n",
                "\n",
                "# Lakehouse\n",
                "BRONZE_LH = \"APAC_CRM_Analytics_LH\"\n",
                "SILVER_LH = \"APAC_Reporting_LH\"\n",
                "\n",
                "# Tables\n",
                "SOURCE_TABLE = f\"{BRONZE_LH}.src_gswin_crb\"\n",
                "TARGET_TABLE = f\"{SILVER_LH}.clean_gswin_chloe\"\n",
                "\n",
                "# Reference tables\n",
                "REF_PRODUCT = f\"{BRONZE_LH}.ref_Chloe_gswin_product_mapping\"\n",
                "REF_INSURER = f\"{BRONZE_LH}.ref_Chloe_insurer_mapping\"\n",
                "REF_INSURER_COUNTRY = f\"{BRONZE_LH}.ref_Chloe_gswin_insurer_mapping\""
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "outputs": [],
            "execution_count": null,
            "source": [
                "# =============================================================================\n",
                "# Cell 2: Load Bronze Data + Filter + Data Type Check\n",
                "# =============================================================================\n",
                "try:\n",
                "    df = spark.sql(f\"SELECT * FROM {SOURCE_TABLE}\")\n",
                "except AnalysisException:\n",
                "    raise Exception(f\"ERROR: Source table {SOURCE_TABLE} not found. Check Lakehouse name and table.\")\n",
                "\n",
                "# Filter: Willis Line = \"CRB\" (safety — Bronze name suggests pre-filtered)\n",
                "if \"Willis Line\" in df.columns:\n",
                "    df = df.filter(F.col(\"`Willis Line`\") == \"CRB\")\n",
                "    print(\"Applied Willis Line = CRB filter\")\n",
                "else:\n",
                "    print(\"No 'Willis Line' column found — Bronze table likely pre-filtered to CRB\")\n",
                "\n",
                "print(\"=== SOURCE SCHEMA ===\")\n",
                "df.printSchema()\n",
                "print(\"\\n=== SOURCE COLUMNS ===\")\n",
                "print(df.columns)\n",
                "print(\"\\n=== SAMPLE DATA (first 3 rows) ===\")\n",
                "display(df.limit(3))\n",
                "print(f\"\\n=== ROW COUNT: {df.count()} ===\")"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "outputs": [],
            "execution_count": null,
            "source": [
                "# =============================================================================\n",
                "# Cell 3: Transformation Logic — Formula Tool 172 (13 expressions)\n",
                "# =============================================================================\n",
                "\n",
                "# --- Step 1: Force correct data types BEFORE transformations ---\n",
                "# Bronze columns: Inception Date, Expiry Date, Issue Date (dates)\n",
                "#                 Premium USD, Total Brokerage in USD (numerics)\n",
                "df = (df\n",
                "    .withColumn(\"Inception Date\", F.col(\"`Inception Date`\").cast(DateType()))\n",
                "    .withColumn(\"Expiry Date\", F.col(\"`Expiry Date`\").cast(DateType()))\n",
                "    .withColumn(\"Issue Date\", F.col(\"`Issue Date`\").cast(DateType()))\n",
                "    .withColumn(\"Premium USD\", F.coalesce(F.col(\"`Premium USD`\"), F.lit(0.0)).cast(DoubleType()))\n",
                "    .withColumn(\"Total Brokerage in USD\", F.coalesce(F.col(\"`Total Brokerage in USD`\"), F.lit(0.0)).cast(DoubleType()))\n",
                ")\n",
                "\n",
                "# --- Step 2: Formula expressions (order matters — sequential evaluation) ---\n",
                "df = (df\n",
                "    # 1. DATA SOURCE = \"GSwin\" (NEW)\n",
                "    .withColumn(\"DATA SOURCE\", F.lit(\"GSwin\"))\n",
                "    # 2. REVENUE COUNTRY = \"Vietnam\" (NEW)\n",
                "    .withColumn(\"REVENUE COUNTRY\", F.lit(\"Vietnam\"))\n",
                "    # 3. Policy Type Name = TRIM(UPPER(Policy Type Name)) (MODIFY)\n",
                "    .withColumn(\"Policy Type Name\", F.upper(F.trim(F.col(\"`Policy Type Name`\"))))\n",
                "    # 4. Insurer Name = TRIM(UPPER(Insurer Name)) (MODIFY)\n",
                "    .withColumn(\"Insurer Name\", F.upper(F.trim(F.col(\"`Insurer Name`\"))))\n",
                "    # 5. InsurerID = TRIM(UPPER(InsurerID)) (MODIFY)\n",
                "    .withColumn(\"InsurerID\", F.upper(F.trim(F.col(\"InsurerID\"))))\n",
                "    # 6. DUNS NUMBER = \"UNKNOWN_GSWIN\" (NEW)\n",
                "    .withColumn(\"DUNS NUMBER\", F.lit(\"UNKNOWN_GSWIN\"))\n",
                "    # 7. SYSTEM ID = \"GSWin-\" + ClientID (NEW)\n",
                "    .withColumn(\"SYSTEM ID\", F.concat(F.lit(\"GSWin-\"), F.col(\"ClientID\")))\n",
                "    # 8. PARTY ID (WTW) = SYSTEM ID (NEW)\n",
                "    .withColumn(\"PARTY ID (WTW)\", F.col(\"`SYSTEM ID`\"))\n",
                "    # 9. REINSURANCE DESCRIPTION: IF Client Type = \"Reinsurance\" THEN \"Reinsurance\" ELSE \"null\" (NEW)\n",
                "    .withColumn(\"REINSURANCE DESCRIPTION\",\n",
                "        F.when(F.col(\"`Client Type`\") == \"Reinsurance\", \"Reinsurance\").otherwise(\"null\"))\n",
                "    # 10. POLICY DESCRIPTION = REINSURANCE DESCRIPTION (NEW)\n",
                "    .withColumn(\"POLICY DESCRIPTION\", F.col(\"`REINSURANCE DESCRIPTION`\"))\n",
                "    # 11. CLIENT ID (WTW): IF PARTY ID IS NULL THEN SYSTEM ID ELSE PARTY ID (NEW)\n",
                "    .withColumn(\"CLIENT ID (WTW)\",\n",
                "        F.when(F.col(\"`PARTY ID (WTW)`\").isNull(), F.col(\"`SYSTEM ID`\"))\n",
                "         .otherwise(F.col(\"`PARTY ID (WTW)`\")))\n",
                "    # 12. FINAL DATE = Inception Date (copy as Date) (NEW)\n",
                "    .withColumn(\"FINAL DATE\", F.col(\"`Inception Date`\").cast(DateType()))\n",
                "    # 13. BUSINESS TYPE = \"UNKNOWN_GSWIN\" (NEW)\n",
                "    .withColumn(\"BUSINESS TYPE\", F.lit(\"UNKNOWN_GSWIN\"))\n",
                ")\n",
                "\n",
                "print(\"=== SCHEMA AFTER FORMULAS ===\")\n",
                "df.printSchema()\n",
                "print(\"\\n=== SAMPLE (first 3 rows) ===\")\n",
                "display(df.limit(3))"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "outputs": [],
            "execution_count": null,
            "source": [
                "# =============================================================================\n",
                "# Cell 4: Union & Unification — SKIPPED (single stream)\n",
                "# =============================================================================\n",
                "# GSwin has only one data stream (no Asia/London split like Eclipse).\n",
                "# No union or column renaming needed at this stage.\n",
                "# Proceeding directly to Cell 5 (Reference Joins).\n",
                "print(\"Cell 4: Skipped — single stream, no union required.\")"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "outputs": [],
            "execution_count": null,
            "source": [
                "# =============================================================================\n",
                "# Cell 5: Reference Joins + Final Select\n",
                "# =============================================================================\n",
                "\n",
                "# --- Load reference tables ---\n",
                "try:\n",
                "    df_product = spark.sql(f\"SELECT * FROM {REF_PRODUCT}\")\n",
                "    df_insurer = spark.sql(f\"SELECT * FROM {REF_INSURER}\")\n",
                "    df_insurer_country = spark.sql(f\"SELECT * FROM {REF_INSURER_COUNTRY}\")\n",
                "except AnalysisException as e:\n",
                "    print(f\"WARNING: Reference table not found — {e}\")\n",
                "    raise\n",
                "\n",
                "# --- Join 1: Product Mapping ---\n",
                "# Key: Policy Type Name (already TRIM+UPPER'd in Cell 3)\n",
                "# Brings in: Level 2 Mapping, GLOBs, GLOBS SPLIT P&C\n",
                "df_product_ref = df_product.select(\n",
                "    F.upper(F.trim(F.col(\"`Policy Type Name`\"))).alias(\"_product_join_key\"),\n",
                "    F.col(\"`Level 2 Mapping`\"),\n",
                "    F.col(\"GLOBs\"),\n",
                "    F.col(\"`GLOBS SPLIT P&C`\")\n",
                ")\n",
                "\n",
                "df = df.join(\n",
                "    df_product_ref,\n",
                "    F.trim(F.upper(df[\"`Policy Type Name`\"])) == df_product_ref[\"_product_join_key\"],\n",
                "    \"left\"\n",
                ").drop(\"_product_join_key\")\n",
                "\n",
                "# --- Join 2: Insurer Mapping ---\n",
                "# Key: Insurer Name (TRIM+UPPER'd) → Insurer\n",
                "# Brings in: MAPPED_INSURER, Lloyd's Asia or Lloyd's London\n",
                "df_insurer_ref = df_insurer.select(\n",
                "    F.upper(F.trim(F.col(\"Insurer\"))).alias(\"_insurer_join_key\"),\n",
                "    F.col(\"MAPPED_INSURER\"),\n",
                "    F.col(\"`Lloyd's Asia or Lloyd's London`\")\n",
                ")\n",
                "\n",
                "df = df.join(\n",
                "    df_insurer_ref,\n",
                "    F.trim(F.upper(df[\"`Insurer Name`\"])) == df_insurer_ref[\"_insurer_join_key\"],\n",
                "    \"left\"\n",
                ").drop(\"_insurer_join_key\")\n",
                "\n",
                "# --- Join 3: Insurer Country Mapping ---\n",
                "# Key: InsurerID (TRIM+UPPER'd)\n",
                "# Brings in: INSURER COUNTRY\n",
                "df_country_ref = df_insurer_country.select(\n",
                "    F.upper(F.trim(F.col(\"InsurerID\"))).alias(\"_country_join_key\"),\n",
                "    F.col(\"`INSURER COUNTRY`\")\n",
                ")\n",
                "\n",
                "df = df.join(\n",
                "    df_country_ref,\n",
                "    F.trim(F.upper(df[\"InsurerID\"])) == df_country_ref[\"_country_join_key\"],\n",
                "    \"left\"\n",
                ").drop(\"_country_join_key\")\n",
                "\n",
                "# --- Final Select: 28 columns with PascalCase aliases ---\n",
                "# Column name mapping: Bronze actual → Alteryx output → PascalCase\n",
                "# Numeric columns coalesced to 0 for null safety\n",
                "df_final = df.select(\n",
                "    F.col(\"`CLIENT ID (WTW)`\").cast(StringType()).alias(\"ClientIdWtw\"),\n",
                "    F.col(\"`Client Name`\").cast(StringType()).alias(\"ClientName\"),\n",
                "    F.col(\"`DATA SOURCE`\").cast(StringType()).alias(\"DataSource\"),\n",
                "    F.col(\"`DUNS NUMBER`\").cast(StringType()).alias(\"DunsNumber\"),\n",
                "    F.col(\"`Expiry Date`\").cast(DateType()).alias(\"ExpiryDate\"),\n",
                "    F.col(\"`FINAL DATE`\").cast(DateType()).alias(\"FinalDate\"),\n",
                "    F.col(\"GLOBs\").cast(StringType()).alias(\"Globs\"),\n",
                "    F.col(\"`GLOBS SPLIT P&C`\").cast(StringType()).alias(\"GlobsSplitPc\"),\n",
                "    F.col(\"`Inception Date`\").cast(DateType()).alias(\"InceptionDate\"),\n",
                "    F.col(\"`INSURER COUNTRY`\").cast(StringType()).alias(\"InsurerCountry\"),\n",
                "    F.col(\"`Insurer Name`\").cast(StringType()).alias(\"InsurerName\"),\n",
                "    F.col(\"`Issue Date`\").cast(DateType()).alias(\"InvoiceDate\"),\n",
                "    F.col(\"`Level 2 Mapping`\").cast(StringType()).alias(\"SubProductClass\"),\n",
                "    F.col(\"`Lloyd's Asia or Lloyd's London`\").cast(StringType()).alias(\"Lloyds\"),\n",
                "    F.col(\"ManagerID\").cast(StringType()).alias(\"AccountHandler\"),\n",
                "    F.col(\"MAPPED_INSURER\").cast(StringType()).alias(\"InsurerMapping\"),\n",
                "    F.col(\"`New/ _Renew`\").cast(StringType()).alias(\"TransactionType\"),\n",
                "    F.col(\"`PARTY ID (WTW)`\").cast(StringType()).alias(\"PartyIdWtw\"),\n",
                "    F.col(\"`POLICY DESCRIPTION`\").cast(StringType()).alias(\"PolicyDescription\"),\n",
                "    F.col(\"`Policy Number`\").cast(StringType()).alias(\"InvoicePolicyNumber\"),\n",
                "    F.col(\"`Policy Type`\").cast(StringType()).alias(\"Department\"),\n",
                "    F.col(\"`Policy Type Name`\").cast(StringType()).alias(\"SystemProductId\"),\n",
                "    F.coalesce(F.col(\"`Premium USD`\"), F.lit(0.0)).cast(DoubleType()).alias(\"PremiumUsd\"),\n",
                "    F.col(\"`REINSURANCE DESCRIPTION`\").cast(StringType()).alias(\"ReinsuranceDescription\"),\n",
                "    F.col(\"`REVENUE COUNTRY`\").cast(StringType()).alias(\"RevenueCountry\"),\n",
                "    F.col(\"`SYSTEM ID`\").cast(StringType()).alias(\"SystemId\"),\n",
                "    F.coalesce(F.col(\"`Total Brokerage in USD`\"), F.lit(0.0)).cast(DoubleType()).alias(\"BrokerageUsd\"),\n",
                "    F.col(\"`BUSINESS TYPE`\").cast(StringType()).alias(\"BusinessType\")\n",
                ")\n",
                "\n",
                "print(\"=== FINAL SCHEMA ===\")\n",
                "df_final.printSchema()\n",
                "print(f\"\\n=== FINAL ROW COUNT: {df_final.count()} ===\")\n",
                "print(\"\\n=== FINAL SAMPLE (first 5 rows) ===\")\n",
                "display(df_final.limit(5))"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "outputs": [],
            "execution_count": null,
            "source": [
                "# =============================================================================\n",
                "# Cell 6: Write to Silver\n",
                "# =============================================================================\n",
                "print(f\"Writing to {TARGET_TABLE}...\")\n",
                "df_final.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(TARGET_TABLE)\n",
                "\n",
                "print(f\"Success. Rows written: {spark.table(TARGET_TABLE).count()}\")\n",
                "print(f\"Columns: {len(spark.table(TARGET_TABLE).columns)}\")\n",
                "display(spark.table(TARGET_TABLE).limit(5))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}