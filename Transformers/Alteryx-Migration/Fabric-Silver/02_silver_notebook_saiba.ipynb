{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02_silver_notebook_saiba\n",
    "\n",
    "**Purpose**: Migrate Saiba Data container from Alteryx ETL Process V3 to Fabric PySpark.\n",
    "\n",
    "**Source**: `APAC_CRM_Analytics_LH.src_Saiba_crb` (Bronze)\n",
    "\n",
    "**Output**: `APAC_Reporting_LH.clean_saiba_chloe` (Silver)\n",
    "\n",
    "**Reference Tables** (all in `APAC_CRM_Analytics_LH`):\n",
    "- `ref_Chloe_saiba_product_mapping` — Product / LOB mapping\n",
    "- `ref_Chloe_insurer_mapping` — Insurer mapping (shared)\n",
    "- `ref_Chloe_asia_currency_mapping` — Currency exchange rates (INR → USD)\n",
    "\n",
    "**Alteryx Tool Mapping**:\n",
    "| Cell | Alteryx Tools |\n",
    "| :--- | :--- |\n",
    "| Cell 2 | Input (183), Select (214), Filter (185) |\n",
    "| Cell 3 | Formula (184) — 15 expressions, Cleanse (281), Select (186) |\n",
    "| Cell 4 | N/A — single stream, no union |\n",
    "| Cell 5 | Product Join (187/188), Insurer Join (190), Currency Join (191), Currency Formula (192), Final Select (193) |\n",
    "| Cell 6 | Output to Silver |"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# =============================================================================\n",
    "# Cell 1: Setup & Configuration\n",
    "# =============================================================================\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType, DoubleType, DateType, IntegerType, LongType, FloatType, DecimalType\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "\n",
    "# Lakehouse\n",
    "BRONZE_LH = \"APAC_CRM_Analytics_LH\"\n",
    "SILVER_LH = \"APAC_Reporting_LH\"\n",
    "\n",
    "# Tables\n",
    "SOURCE_TABLE = f\"{BRONZE_LH}.src_Saiba_crb\"\n",
    "TARGET_TABLE = f\"{SILVER_LH}.clean_saiba_chloe\"\n",
    "\n",
    "# Reference tables\n",
    "REF_PRODUCT = f\"{BRONZE_LH}.ref_Chloe_saiba_product_mapping\"\n",
    "REF_INSURER = f\"{BRONZE_LH}.ref_Chloe_insurer_mapping\"\n",
    "REF_CURRENCY = f\"{BRONZE_LH}.ref_Chloe_asia_currency_mapping\""
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# =============================================================================\n",
    "# Cell 2: Load Bronze Data + Filter + Data Type Check\n",
    "# =============================================================================\n",
    "try:\n",
    "    df = spark.sql(f\"SELECT * FROM {SOURCE_TABLE}\")\n",
    "except AnalysisException:\n",
    "    raise Exception(f\"ERROR: Source table {SOURCE_TABLE} not found.\")\n",
    "\n",
    "# Filter: Department != \"EB\" (exclude Employee Benefit)\n",
    "if \"Department\" in df.columns:\n",
    "    df = df.filter(F.col(\"Department\") != \"EB\")\n",
    "    print(\"Applied Department != 'EB' filter\")\n",
    "else:\n",
    "    print(\"WARNING: No 'Department' column found — check column names\")\n",
    "\n",
    "print(\"=== SOURCE SCHEMA ===\")\n",
    "df.printSchema()\n",
    "print(\"\\n=== SOURCE COLUMNS ===\")\n",
    "print(df.columns)\n",
    "print(\"\\n=== SAMPLE DATA (first 3 rows) ===\")\n",
    "display(df.limit(3))\n",
    "print(f\"\\n=== ROW COUNT: {df.count()} ===\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# =============================================================================\n",
    "# Cell 3: Transformation Logic\n",
    "#   - Select 214: cast CustCode to string, drop Cust.Vertical\n",
    "#   - Formula 184: 15 expressions\n",
    "#   - Cleanse 281: uppercase Insurer Name (handled by Formula)\n",
    "#   - Select 186: BizType → TRANSACTION TYPE\n",
    "# =============================================================================\n",
    "\n",
    "# --- Step 1: Select 214 — cast CustCode to string ---\n",
    "df = df.withColumn(\"CustCode\", F.col(\"CustCode\").cast(StringType()))\n",
    "\n",
    "# --- Step 2: Force correct data types BEFORE formulas ---\n",
    "df = (df\n",
    "    .withColumn(\"EntryDate\", F.col(\"EntryDate\").cast(DateType()))\n",
    "    .withColumn(\"StartDate\", F.col(\"StartDate\").cast(DateType()))\n",
    "    .withColumn(\"ExpiryDate\", F.col(\"ExpiryDate\").cast(DateType()))\n",
    "    .withColumn(\"Brok Prem.\", F.col(\"`Brok Prem.`\").cast(DoubleType()))\n",
    "    .withColumn(\"Brokerage\", F.col(\"Brokerage\").cast(DoubleType()))\n",
    ")\n",
    "\n",
    "# --- Step 3: Formula 184 — 15 expressions (order matters) ---\n",
    "df = (df\n",
    "    # 1. DATA SOURCE = \"Saiba\" (NEW)\n",
    "    .withColumn(\"DATA SOURCE\", F.lit(\"Saiba\"))\n",
    "    # 2. REVENUE COUNTRY = \"India\" (NEW)\n",
    "    .withColumn(\"REVENUE COUNTRY\", F.lit(\"India\"))\n",
    "    # 3. Policy Type = TRIM(UPPER(Policy Type)) (MODIFY)\n",
    "    .withColumn(\"Policy Type\", F.upper(F.trim(F.col(\"`Policy Type`\"))))\n",
    "    # 4. Insurer Name = UPPER(TRIM(Insurer)) (NEW — from Insurer column)\n",
    "    .withColumn(\"Insurer Name\", F.upper(F.trim(F.col(\"Insurer\"))))\n",
    "    # 5. DUNS NUMBER = \"UNKNOWN_SAIBA\" (NEW)\n",
    "    .withColumn(\"DUNS NUMBER\", F.lit(\"UNKNOWN_SAIBA\"))\n",
    "    # 6. SYSTEM ID = \"Saiba-\" + CustCode (NEW)\n",
    "    .withColumn(\"SYSTEM ID\", F.concat(F.lit(\"Saiba-\"), F.col(\"CustCode\")))\n",
    "    # 7. PARTY ID (WTW) = SYSTEM ID (NEW)\n",
    "    .withColumn(\"PARTY ID (WTW)\", F.col(\"`SYSTEM ID`\"))\n",
    "    # 8. REINSURANCE DESCRIPTION = \"Null\" (NEW)\n",
    "    .withColumn(\"REINSURANCE DESCRIPTION\", F.lit(\"Null\"))\n",
    "    # 9. POLICY DESCRIPTION = \"NuLL\" (NEW)\n",
    "    .withColumn(\"POLICY DESCRIPTION\", F.lit(\"NuLL\"))\n",
    "    # 10. CLIENT ID (WTW) = SYSTEM ID (NEW)\n",
    "    .withColumn(\"CLIENT ID (WTW)\", F.col(\"`SYSTEM ID`\"))\n",
    "    # 11. FINAL YEAR = YEAR(EntryDate) (NEW — as string)\n",
    "    .withColumn(\"FINAL YEAR\", F.year(F.col(\"EntryDate\")).cast(StringType()))\n",
    "    # 12. FINAL DATE = EntryDate (NEW — copy as Date)\n",
    "    .withColumn(\"FINAL DATE\", F.col(\"EntryDate\").cast(DateType()))\n",
    "    # 13. BUSINESS TYPE = \"Null\" (NEW)\n",
    "    .withColumn(\"BUSINESS TYPE\", F.lit(\"Null\"))\n",
    "    # 14. INSURER COUNTRY = \"India\" (NEW)\n",
    "    .withColumn(\"INSURER COUNTRY\", F.lit(\"India\"))\n",
    "    # 15. CCYYEAR = \"INR-\" + FINAL YEAR (NEW)\n",
    "    .withColumn(\"CCYYEAR\", F.concat(F.lit(\"INR-\"), F.col(\"`FINAL YEAR`\")))\n",
    ")\n",
    "\n",
    "# --- Step 4: Select 186 — rename BizType → TRANSACTION TYPE ---\n",
    "df = df.withColumnRenamed(\"BizType\", \"TRANSACTION TYPE\")\n",
    "\n",
    "print(\"=== SCHEMA AFTER FORMULAS ===\")\n",
    "df.printSchema()\n",
    "print(\"\\n=== SAMPLE (first 3 rows) ===\")\n",
    "display(df.limit(3))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# =============================================================================\n",
    "# Cell 4: Union & Unification — SKIPPED (single stream)\n",
    "# =============================================================================\n",
    "# Saiba has only one data stream.\n",
    "# No union or column renaming needed at this stage.\n",
    "print(\"Cell 4: Skipped — single stream, no union required.\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# =============================================================================\n",
    "# Cell 5: Reference Joins + Currency Conversion + Final Select\n",
    "# =============================================================================\n",
    "\n",
    "# --- Load reference tables ---\n",
    "try:\n",
    "    df_product = spark.sql(f\"SELECT * FROM {REF_PRODUCT}\")\n",
    "    df_insurer = spark.sql(f\"SELECT * FROM {REF_INSURER}\")\n",
    "    df_currency = spark.sql(f\"SELECT * FROM {REF_CURRENCY}\")\n",
    "except AnalysisException as e:\n",
    "    print(f\"WARNING: Reference table not found — {e}\")\n",
    "    raise\n",
    "\n",
    "# --- Join 1: Product Mapping (Tool 187) ---\n",
    "# Key: Policy Type (already TRIM+UPPER'd in Cell 3)\n",
    "# Brings in: Lvl2 Product Mapping, GLoBs, GLOBS SPLIT P&C\n",
    "df_product_ref = df_product.select(\n",
    "    F.upper(F.trim(F.col(\"`Policy Type`\"))).alias(\"_product_join_key\"),\n",
    "    F.col(\"`Lvl2 Product Mapping`\"),\n",
    "    F.col(\"GLoBs\"),\n",
    "    F.col(\"`GLOBS SPLIT P&C`\")\n",
    ")\n",
    "\n",
    "df = df.join(\n",
    "    df_product_ref,\n",
    "    F.trim(F.upper(df[\"`Policy Type`\"])) == df_product_ref[\"_product_join_key\"],\n",
    "    \"left\"\n",
    ").drop(\"_product_join_key\")\n",
    "\n",
    "# --- Join 2: Insurer Mapping (Tool 190) ---\n",
    "# Key: Insurer (ORIGINAL source column, NOT Insurer Name)\n",
    "# Brings in: MAPPED_INSURER, Lloyd's Asia or Lloyd's London\n",
    "df_insurer_ref = df_insurer.select(\n",
    "    F.upper(F.trim(F.col(\"Insurer\"))).alias(\"_insurer_join_key\"),\n",
    "    F.col(\"MAPPED_INSURER\"),\n",
    "    F.col(\"`Lloyd's Asia or Lloyd's London`\")\n",
    ")\n",
    "\n",
    "df = df.join(\n",
    "    df_insurer_ref,\n",
    "    F.trim(F.upper(df[\"Insurer\"])) == df_insurer_ref[\"_insurer_join_key\"],\n",
    "    \"left\"\n",
    ").drop(\"_insurer_join_key\")\n",
    "\n",
    "# --- Join 3: Currency Mapping (Tool 191) ---\n",
    "# Key: CCYYEAR (= \"INR-\" + YEAR(EntryDate))\n",
    "# Brings in: Value (exchange rate for USD conversion)\n",
    "df_currency_ref = df_currency.select(\n",
    "    F.upper(F.trim(F.col(\"CCYYEAR\"))).alias(\"_currency_join_key\"),\n",
    "    F.col(\"Value\")\n",
    ")\n",
    "\n",
    "df = df.join(\n",
    "    df_currency_ref,\n",
    "    F.trim(F.upper(df[\"CCYYEAR\"])) == df_currency_ref[\"_currency_join_key\"],\n",
    "    \"left\"\n",
    ").drop(\"_currency_join_key\")\n",
    "\n",
    "# --- Currency Formula (Tool 192) ---\n",
    "# Convert INR to USD using the exchange rate Value\n",
    "df = (df\n",
    "    .withColumn(\"PREMIUM (USD)\", (F.col(\"`Brok Prem.`\") * F.col(\"Value\")).cast(DoubleType()))\n",
    "    .withColumn(\"BROKERAGE (USD)\", (F.col(\"Brokerage\") * F.col(\"Value\")).cast(DoubleType()))\n",
    ")\n",
    "\n",
    "# --- Final Select: 28 columns with PascalCase aliases ---\n",
    "df_final = df.select(\n",
    "    F.col(\"`BROKERAGE (USD)`\").cast(DoubleType()).alias(\"BrokerageUsd\"),\n",
    "    F.col(\"`BUSINESS TYPE`\").cast(StringType()).alias(\"BusinessType\"),\n",
    "    F.col(\"`CLIENT ID (WTW)`\").cast(StringType()).alias(\"ClientIdWtw\"),\n",
    "    F.col(\"CustName\").cast(StringType()).alias(\"ClientName\"),\n",
    "    F.col(\"`DATA SOURCE`\").cast(StringType()).alias(\"DataSource\"),\n",
    "    F.col(\"Department\").cast(StringType()).alias(\"Department\"),\n",
    "    F.col(\"`DUNS NUMBER`\").cast(StringType()).alias(\"DunsNumber\"),\n",
    "    F.col(\"EntryDate\").cast(DateType()).alias(\"InvoiceDate\"),\n",
    "    F.col(\"ExpiryDate\").cast(DateType()).alias(\"ExpiryDate\"),\n",
    "    F.col(\"`FINAL DATE`\").cast(DateType()).alias(\"FinalDate\"),\n",
    "    F.col(\"GLoBs\").cast(StringType()).alias(\"Globs\"),\n",
    "    F.col(\"`GLOBS SPLIT P&C`\").cast(StringType()).alias(\"GlobsSplitPc\"),\n",
    "    F.col(\"`INSURER COUNTRY`\").cast(StringType()).alias(\"InsurerCountry\"),\n",
    "    F.col(\"`Insurer Name`\").cast(StringType()).alias(\"InsurerName\"),\n",
    "    F.col(\"`Lloyd's Asia or Lloyd's London`\").cast(StringType()).alias(\"Lloyds\"),\n",
    "    F.col(\"`Lvl2 Product Mapping`\").cast(StringType()).alias(\"SubProductClass\"),\n",
    "    F.col(\"MAPPED_INSURER\").cast(StringType()).alias(\"InsurerMapping\"),\n",
    "    F.col(\"`PARTY ID (WTW)`\").cast(StringType()).alias(\"PartyIdWtw\"),\n",
    "    F.col(\"`POLICY DESCRIPTION`\").cast(StringType()).alias(\"PolicyDescription\"),\n",
    "    F.col(\"`Policy Type`\").cast(StringType()).alias(\"SystemProductId\"),\n",
    "    F.col(\"PolicyNo\").cast(StringType()).alias(\"InvoicePolicyNumber\"),\n",
    "    F.col(\"`PREMIUM (USD)`\").cast(DoubleType()).alias(\"PremiumUsd\"),\n",
    "    F.col(\"`REINSURANCE DESCRIPTION`\").cast(StringType()).alias(\"ReinsuranceDescription\"),\n",
    "    F.col(\"`REVENUE COUNTRY`\").cast(StringType()).alias(\"RevenueCountry\"),\n",
    "    F.col(\"RMName\").cast(StringType()).alias(\"AccountHandler\"),\n",
    "    F.col(\"StartDate\").cast(DateType()).alias(\"InceptionDate\"),\n",
    "    F.col(\"`SYSTEM ID`\").cast(StringType()).alias(\"SystemId\"),\n",
    "    F.col(\"`TRANSACTION TYPE`\").cast(StringType()).alias(\"TransactionType\")\n",
    ")\n",
    "\n",
    "print(\"=== FINAL SCHEMA ===\")\n",
    "df_final.printSchema()\n",
    "print(f\"\\n=== FINAL ROW COUNT: {df_final.count()} ===\")\n",
    "print(\"\\n=== FINAL SAMPLE (first 5 rows) ===\")\n",
    "display(df_final.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "# =============================================================================\n",
    "# Cell 6: Write to Silver\n",
    "# =============================================================================\n",
    "print(f\"Writing to {TARGET_TABLE}...\")\n",
    "df_final.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(TARGET_TABLE)\n",
    "\n",
    "print(f\"Success. Rows written: {spark.table(TARGET_TABLE).count()}\")\n",
    "print(f\"Columns: {len(spark.table(TARGET_TABLE).columns)}\")\n",
    "display(spark.table(TARGET_TABLE).limit(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
