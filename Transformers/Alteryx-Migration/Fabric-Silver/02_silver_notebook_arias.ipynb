{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 02_silver_notebook_arias\n",
                "\n",
                "**Purpose**: Migrate Arias Data from Alteryx ETL Process to Fabric PySpark.\n",
                "\n",
                "**Source**: `APAC_CRM_Analytics_LH.src_arias_crb` (Bronze, Japanese columns)\n",
                "\n",
                "**Output**: `APAC_Reporting_LH.clean_arias` (Silver)\n",
                "\n",
                "**Reference Tables** (all in `APAC_CRM_Analytics_LH`):\n",
                "- `ref_Chloe_asia_currency_mapping` — Currency exchange rates (JPY → USD)\n",
                "- `ref_Chloe_arias_product_mapping` — Product / LOB mapping\n",
                "- `ref_Chloe_insurer_mapping` — Insurer mapping (shared)\n",
                "\n",
                "**Alteryx Tool Mapping**:\n",
                "| Cell | Alteryx Tools |\n",
                "| :--- | :--- |\n",
                "| Cell 2 | Input (src_arias_crb), Rename Japanese columns |\n",
                "| Cell 3 | Formula (Tool 147) — date conversion, hardcoded fields, derived fields |\n",
                "| Cell 4 | N/A — single stream, no union |\n",
                "| Cell 5 | Currency Join, Product Join, Insurer Join, Final Select |\n",
                "| Cell 6 | Output to Silver |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# Cell 1: Setup & Configuration\n",
                "# =============================================================================\n",
                "from pyspark.sql import functions as F\n",
                "from pyspark.sql.types import StringType, DoubleType, DateType, IntegerType, LongType, FloatType, DecimalType\n",
                "from pyspark.sql.utils import AnalysisException\n",
                "\n",
                "# Lakehouse\n",
                "BRONZE_LH = \"APAC_CRM_Analytics_LH\"\n",
                "SILVER_LH = \"APAC_Reporting_LH\"\n",
                "\n",
                "# Tables\n",
                "SOURCE_TABLE = f\"{BRONZE_LH}.src_arias_crb\"\n",
                "TARGET_TABLE = f\"{SILVER_LH}.clean_arias\"\n",
                "\n",
                "# Reference tables\n",
                "REF_CURRENCY = f\"{BRONZE_LH}.ref_Chloe_asia_currency_mapping\"\n",
                "REF_PRODUCT = f\"{BRONZE_LH}.ref_Chloe_arias_product_mapping\"\n",
                "REF_INSURER = f\"{BRONZE_LH}.ref_Chloe_insurer_mapping\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# Cell 2: Load Bronze Data & Rename Columns\n",
                "# =============================================================================\n",
                "try:\n",
                "    df_arias = spark.sql(f\"SELECT * FROM {SOURCE_TABLE}\")\n",
                "\n",
                "    print(\"=== SOURCE SCHEMA ===\")\n",
                "    df_arias.printSchema()\n",
                "    print(\"\\n=== SOURCE COLUMNS ===\")\n",
                "    print(df_arias.columns)\n",
                "    print(\"\\n=== SAMPLE DATA (first 3 rows) ===\")\n",
                "    display(df_arias.limit(3))\n",
                "\n",
                "    # Rename Japanese columns to English\n",
                "    df_arias_renamed = df_arias \\\n",
                "        .withColumnRenamed(\"請求書番号\", \"Invoice No.\") \\\n",
                "        .withColumnRenamed(\"保険始期\", \"From\") \\\n",
                "        .withColumnRenamed(\"保険終期\", \"To\") \\\n",
                "        .withColumnRenamed(\"契約者名\", \"Name of Client\") \\\n",
                "        .withColumnRenamed(\"保険会社名\", \"Insurer\") \\\n",
                "        .withColumnRenamed(\"保険種類\", \"Class of Insurance\") \\\n",
                "        .withColumnRenamed(\"保険料\", \"Premium\") \\\n",
                "        .withColumnRenamed(\"手数料（税抜_\", \"Full Commission\") \\\n",
                "        .withColumnRenamed(\"収益認識日\", \"Premium Receipt/Paid Date\") \\\n",
                "        .withColumnRenamed(\"Policy No\", \"Policy No.\") \\\n",
                "        .withColumnRenamed(\"チーム名\", \"Team\") \\\n",
                "        .withColumnRenamed(\"ＡＥ名\", \"A/E\") \\\n",
                "        .withColumnRenamed(\"Recurring\", \"Recurring/Non-Recurring\") \\\n",
                "        .withColumnRenamed(\"６分類\", \"6分類\")\n",
                "\n",
                "    print(\"\\n=== RENAMED SCHEMA ===\")\n",
                "    df_arias_renamed.printSchema()\n",
                "    print(f\"\\n=== ROW COUNT: {df_arias_renamed.count()} ===\")\n",
                "\n",
                "except AnalysisException:\n",
                "    raise Exception(f\"ERROR: Source table {SOURCE_TABLE} not found.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# Cell 3: Transformation Logic (Alteryx Tool 147 - Arias Data Formula)\n",
                "#   - Force correct data types BEFORE transformation\n",
                "#   - Date conversion with multi-format coalesce\n",
                "#   - Hardcoded fields, derived fields, column renames\n",
                "# =============================================================================\n",
                "\n",
                "# --- Step 1: Force correct data types BEFORE formulas ---\n",
                "# Premium and Full Commission may come in as strings from Excel source\n",
                "df_typed = df_arias_renamed \\\n",
                "    .withColumn(\"Premium\", F.col(\"Premium\").cast(DoubleType())) \\\n",
                "    .withColumn(\"Full Commission\", F.col(\"`Full Commission`\").cast(DoubleType()))\n",
                "\n",
                "# --- Step 2: Date Conversion ---\n",
                "# Source dates may be: yyyyMMdd numeric, yyyy-MM-dd string, or already DateType\n",
                "# Try multiple formats with coalesce for robustness\n",
                "df_transformed = (df_typed\n",
                "    .withColumn(\"InvoiceDate\", F.coalesce(\n",
                "        F.to_date(F.col(\"Premium Receipt/Paid Date\").cast(StringType()), \"yyyyMMdd\"),\n",
                "        F.to_date(F.col(\"Premium Receipt/Paid Date\").cast(StringType()), \"yyyy-MM-dd\"),\n",
                "        F.col(\"Premium Receipt/Paid Date\").cast(DateType())\n",
                "    ))\n",
                "    .withColumn(\"InceptionDate\", F.coalesce(\n",
                "        F.to_date(F.col(\"From\").cast(StringType()), \"yyyyMMdd\"),\n",
                "        F.to_date(F.col(\"From\").cast(StringType()), \"yyyy-MM-dd\"),\n",
                "        F.col(\"From\").cast(DateType())\n",
                "    ))\n",
                "    .withColumn(\"ExpiryDate\", F.coalesce(\n",
                "        F.to_date(F.col(\"To\").cast(StringType()), \"yyyyMMdd\"),\n",
                "        F.to_date(F.col(\"To\").cast(StringType()), \"yyyy-MM-dd\"),\n",
                "        F.col(\"To\").cast(DateType())\n",
                "    ))\n",
                "    .withColumn(\"FinalDate\", F.col(\"InceptionDate\"))\n",
                ")\n",
                "\n",
                "print(\"=== DATE PARSING CHECK ===\")\n",
                "df_transformed.select(\n",
                "    F.col(\"Premium Receipt/Paid Date\"), F.col(\"InvoiceDate\"),\n",
                "    F.col(\"From\"), F.col(\"InceptionDate\"),\n",
                "    F.col(\"To\"), F.col(\"ExpiryDate\"),\n",
                "    F.col(\"Premium\"), F.col(\"Full Commission\")\n",
                ").show(5, truncate=False)\n",
                "\n",
                "# --- Step 3: Hardcoded Fields (Alteryx Formula Tool 147) ---\n",
                "df_transformed = (df_transformed\n",
                "    .withColumn(\"DataSource\", F.lit(\"Arias\"))\n",
                "    .withColumn(\"RevenueCountry\", F.lit(\"Japan\"))\n",
                "    .withColumn(\"Segment\", F.lit(\"null\"))\n",
                "    .withColumn(\"InsurerCountry\", F.lit(\"JAPAN\"))\n",
                "    .withColumn(\"DunsNumber\", F.lit(\"UNKNOWN-ARIAS\"))\n",
                "    .withColumn(\"BusinessType\", F.lit(\"UNKNOWN\"))\n",
                "    .withColumn(\"PartyIdWtw\", F.lit(\"UNKNOWN-ARIAS\"))\n",
                "    .withColumn(\"Ccy\", F.lit(\"JPY\"))\n",
                "    .withColumn(\"ReinsuranceDescription\", F.lit(\"null\"))\n",
                "    .withColumn(\"PolicyDescription\", F.lit(\"null\"))\n",
                "    .withColumn(\"Department\", F.lit(\"null\"))\n",
                "    .withColumn(\"TransactionType\",\n",
                "        F.when(F.col(\"`Recurring/Non-Recurring`\") == \"R\", F.lit(\"RENEWAL\"))\n",
                "        .when(F.col(\"`Recurring/Non-Recurring`\") == \"N\", F.lit(\"NEW\"))\n",
                "        .otherwise(F.col(\"`Recurring/Non-Recurring`\"))\n",
                "    )\n",
                ")\n",
                "\n",
                "# --- Step 4: Derived Fields ---\n",
                "# CLIENT ID = [Name of Client], SYSTEM ID = [Name of Client]\n",
                "# INCEPTION YEAR = DateTimeYear([INCEPTION DATE])\n",
                "# CCYYEAR = \"JPY\" + \"-\" + [INCEPTION YEAR]\n",
                "df_transformed = (df_transformed\n",
                "    .withColumn(\"ClientIdWtw\", F.col(\"Name of Client\"))\n",
                "    .withColumn(\"SystemId\", F.col(\"Name of Client\"))\n",
                "    .withColumn(\"InceptionYear\", F.year(F.col(\"InceptionDate\")).cast(StringType()))\n",
                "    .withColumn(\"Ccyyear\", F.concat(F.lit(\"JPY-\"), F.col(\"InceptionYear\")))\n",
                ")\n",
                "\n",
                "# --- Step 5: Rename remaining columns ---\n",
                "df_transformed = (df_transformed\n",
                "    .withColumnRenamed(\"Name of Client\", \"ClientName\")\n",
                "    .withColumnRenamed(\"Insurer\", \"InsurerName\")\n",
                "    .withColumnRenamed(\"Class of Insurance\", \"SystemProductId\")\n",
                "    .withColumnRenamed(\"A/E\", \"AccountHandler\")\n",
                "    .withColumnRenamed(\"Policy No.\", \"InvoicePolicyNumber\")\n",
                ")\n",
                "\n",
                "print(\"=== SCHEMA AFTER FORMULAS ===\")\n",
                "df_transformed.printSchema()\n",
                "print(\"\\n=== SAMPLE (first 3 rows) ===\")\n",
                "display(df_transformed.limit(3))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# Cell 4: Union & Unification — SKIPPED (single stream)\n",
                "# =============================================================================\n",
                "# Arias has only one data stream.\n",
                "# No union or column renaming needed at this stage.\n",
                "print(\"Cell 4: Skipped — single stream, no union required.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# Cell 5: Reference Joins + Currency Conversion + Final Select\n",
                "# =============================================================================\n",
                "\n",
                "# --- Load reference tables ---\n",
                "try:\n",
                "    df_currency = spark.sql(f\"SELECT * FROM {REF_CURRENCY}\")\n",
                "    df_product = spark.sql(f\"SELECT * FROM {REF_PRODUCT}\")\n",
                "    df_insurer = spark.sql(f\"SELECT * FROM {REF_INSURER}\")\n",
                "except AnalysisException as e:\n",
                "    print(f\"WARNING: Reference table not found — {e}\")\n",
                "    raise\n",
                "\n",
                "# --- Join 1: Currency Mapping ---\n",
                "# Key: Ccyyear (= \"JPY-\" + YEAR(InceptionDate))\n",
                "# Brings in: Value (exchange rate for USD conversion)\n",
                "df_currency_ref = df_currency.select(\n",
                "    F.upper(F.trim(F.col(\"CCYYEAR\"))).alias(\"_currency_join_key\"),\n",
                "    F.col(\"Value\").alias(\"Ccyvalue\")\n",
                ")\n",
                "\n",
                "df = df_transformed.join(\n",
                "    df_currency_ref,\n",
                "    F.trim(F.upper(df_transformed[\"Ccyyear\"])) == df_currency_ref[\"_currency_join_key\"],\n",
                "    \"left\"\n",
                ").drop(\"_currency_join_key\")\n",
                "\n",
                "# --- Join 2: Product Mapping ---\n",
                "# Key: SystemProductId (= Class of Insurance, already renamed)\n",
                "# Brings in: Lvl 2 Mapping, GLOBs, GLOBS SPLIT P&C\n",
                "df_product_ref = df_product.select(\n",
                "    F.upper(F.trim(F.col(\"`Class of Insurance`\"))).alias(\"_product_join_key\"),\n",
                "    F.col(\"`Lvl 2 Mapping`\"),\n",
                "    F.col(\"GLOBs\"),\n",
                "    F.col(\"`GLOBS SPLIT P&C`\")\n",
                ")\n",
                "\n",
                "df = df.join(\n",
                "    df_product_ref,\n",
                "    F.trim(F.upper(df[\"SystemProductId\"])) == df_product_ref[\"_product_join_key\"],\n",
                "    \"left\"\n",
                ").drop(\"_product_join_key\")\n",
                "\n",
                "# --- Join 3: Insurer Mapping ---\n",
                "# Key: InsurerName (= Insurer, already renamed)\n",
                "# Brings in: MAPPED_INSURER, Lloyd's Asia or Lloyd's London\n",
                "df_insurer_ref = df_insurer.select(\n",
                "    F.upper(F.trim(F.col(\"Insurer\"))).alias(\"_insurer_join_key\"),\n",
                "    F.col(\"MAPPED_INSURER\"),\n",
                "    F.col(\"`Lloyd's Asia or Lloyd's London`\")\n",
                ")\n",
                "\n",
                "df = df.join(\n",
                "    df_insurer_ref,\n",
                "    F.trim(F.upper(df[\"InsurerName\"])) == df_insurer_ref[\"_insurer_join_key\"],\n",
                "    \"left\"\n",
                ").drop(\"_insurer_join_key\")\n",
                "\n",
                "# --- Currency Formula ---\n",
                "# Convert JPY to USD using the exchange rate Ccyvalue\n",
                "df = (df\n",
                "    .withColumn(\"PremiumUsd\", (F.col(\"Premium\") * F.coalesce(F.col(\"Ccyvalue\"), F.lit(0))).cast(DoubleType()))\n",
                "    .withColumn(\"BrokerageUsd\", (F.col(\"`Full Commission`\") * F.coalesce(F.col(\"Ccyvalue\"), F.lit(0))).cast(DoubleType()))\n",
                ")\n",
                "\n",
                "# --- Final Select: PascalCase aliases ---\n",
                "df_final = df.select(\n",
                "    F.col(\"BrokerageUsd\").cast(DoubleType()).alias(\"BrokerageUsd\"),\n",
                "    F.col(\"BusinessType\").cast(StringType()).alias(\"BusinessType\"),\n",
                "    F.col(\"ClientIdWtw\").cast(StringType()).alias(\"ClientIdWtw\"),\n",
                "    F.col(\"ClientName\").cast(StringType()).alias(\"ClientName\"),\n",
                "    F.col(\"DataSource\").cast(StringType()).alias(\"DataSource\"),\n",
                "    F.col(\"Department\").cast(StringType()).alias(\"Department\"),\n",
                "    F.col(\"DunsNumber\").cast(StringType()).alias(\"DunsNumber\"),\n",
                "    F.col(\"InvoiceDate\").cast(DateType()).alias(\"InvoiceDate\"),\n",
                "    F.col(\"ExpiryDate\").cast(DateType()).alias(\"ExpiryDate\"),\n",
                "    F.col(\"FinalDate\").cast(DateType()).alias(\"FinalDate\"),\n",
                "    F.col(\"GLOBs\").cast(StringType()).alias(\"Globs\"),\n",
                "    F.col(\"`GLOBS SPLIT P&C`\").cast(StringType()).alias(\"GlobsSplitPc\"),\n",
                "    F.col(\"InsurerCountry\").cast(StringType()).alias(\"InsurerCountry\"),\n",
                "    F.col(\"InsurerName\").cast(StringType()).alias(\"InsurerName\"),\n",
                "    F.col(\"`Lloyd's Asia or Lloyd's London`\").cast(StringType()).alias(\"Lloyds\"),\n",
                "    F.col(\"`Lvl 2 Mapping`\").cast(StringType()).alias(\"SubProductClass\"),\n",
                "    F.col(\"MAPPED_INSURER\").cast(StringType()).alias(\"InsurerMapping\"),\n",
                "    F.col(\"PartyIdWtw\").cast(StringType()).alias(\"PartyIdWtw\"),\n",
                "    F.col(\"PolicyDescription\").cast(StringType()).alias(\"PolicyDescription\"),\n",
                "    F.col(\"SystemProductId\").cast(StringType()).alias(\"SystemProductId\"),\n",
                "    F.col(\"InvoicePolicyNumber\").cast(StringType()).alias(\"InvoicePolicyNumber\"),\n",
                "    F.col(\"PremiumUsd\").cast(DoubleType()).alias(\"PremiumUsd\"),\n",
                "    F.col(\"ReinsuranceDescription\").cast(StringType()).alias(\"ReinsuranceDescription\"),\n",
                "    F.col(\"RevenueCountry\").cast(StringType()).alias(\"RevenueCountry\"),\n",
                "    F.col(\"AccountHandler\").cast(StringType()).alias(\"AccountHandler\"),\n",
                "    F.col(\"InceptionDate\").cast(DateType()).alias(\"InceptionDate\"),\n",
                "    F.col(\"SystemId\").cast(StringType()).alias(\"SystemId\"),\n",
                "    F.col(\"TransactionType\").cast(StringType()).alias(\"TransactionType\")\n",
                ").drop(\"Segment\")\n",
                "\n",
                "print(\"=== FINAL SCHEMA ===\")\n",
                "df_final.printSchema()\n",
                "print(f\"\\n=== FINAL ROW COUNT: {df_final.count()} ===\")\n",
                "print(\"\\n=== FINAL SAMPLE (first 5 rows) ===\")\n",
                "display(df_final.limit(5))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# Cell 6: Write to Silver\n",
                "# =============================================================================\n",
                "print(f\"Writing to {TARGET_TABLE}...\")\n",
                "df_final.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(TARGET_TABLE)\n",
                "\n",
                "print(f\"Success. Rows written: {spark.table(TARGET_TABLE).count()}\")\n",
                "print(f\"Columns: {len(spark.table(TARGET_TABLE).columns)}\")\n",
                "display(spark.table(TARGET_TABLE).limit(5))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
