{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 02 · Silver — Clean eGlobal\n",
                "\n",
                "| Item | Detail |\n",
                "|------|--------|\n",
                "| **Source** | `APAC_CRM_Analytics_LH.src_eglobal_premium_report` |\n",
                "| **Target** | `APAC_Reporting_LH.clean_eglobal_chloe` |\n",
                "| **Grain** | One row per invoice line |\n",
                "\n",
                "### Alteryx Tool Mapping\n",
                "\n",
                "| Cell | Alteryx Tool(s) | Description |\n",
                "|------|----------------|-------------|\n",
                "| 2 | Input (35,70,73,76,293,303), Filter (302,84) | Read Bronze, filter ACCIDENT (AU) & Employee Benefits |\n",
                "| 3 | Formula (51,68,71,74,77,296), Formula (89,88,87,86,83,294), Join (304), Formula (204) | Date fallbacks, Revenue Country, CCY, branch mapping (HK), TRIM/UPPER |\n",
                "| 5 | Join (61,198,199), Formula (66), Select (195) | Currency/Product/Insurer joins, USD calc, derived cols, final select |\n",
                "| 6 | Output | Write Delta to Silver |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# Cell 1: Setup & Configuration\n",
                "# =============================================================================\n",
                "from pyspark.sql import functions as F\n",
                "from pyspark.sql.types import StringType, DoubleType, DateType, IntegerType, LongType, FloatType, DecimalType\n",
                "from pyspark.sql.utils import AnalysisException\n",
                "\n",
                "# Lakehouse\n",
                "BRONZE_LH = \"APAC_CRM_Analytics_LH\"\n",
                "SILVER_LH = \"APAC_Reporting_LH\"\n",
                "\n",
                "# Tables\n",
                "SOURCE_TABLE = f\"{BRONZE_LH}.src_eglobal_premium_report\"\n",
                "TARGET_TABLE = f\"{SILVER_LH}.clean_eglobal_chloe\"\n",
                "\n",
                "# Reference tables\n",
                "REF_BRANCH_MAPPING   = f\"{BRONZE_LH}.ref_eglobal_premium_branch_mapping\"\n",
                "REF_CURRENCY_MAPPING = f\"{BRONZE_LH}.ref_Chloe_asia_currency_mapping\"\n",
                "REF_PRODUCT_MAPPING  = f\"{BRONZE_LH}.ref_Chloe_eglobal_product_mapping\"\n",
                "REF_INSURER_MAPPING  = f\"{BRONZE_LH}.ref_Chloe_insurer_mapping\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# Cell 2: Read Bronze + Filters\n",
                "# Alteryx: Input tools (35,70,73,76,293,303) → Filter (302) ACCIDENT for AU\n",
                "#          → Union (79) → Filter (84) Employee Benefits\n",
                "# =============================================================================\n",
                "df = spark.table(SOURCE_TABLE)\n",
                "print(f\"Source rows: {df.count()}\")\n",
                "print(f\"Source columns: {len(df.columns)}\")\n",
                "\n",
                "# --- Filter ACCIDENT: only for Australia (Alteryx Tool 302) ---\n",
                "# For AU rows, exclude records where LINE OF BUSINESS contains 'ACCIDENT'\n",
                "# For non-AU rows, keep all records\n",
                "df = df.filter(\n",
                "    (~F.upper(F.col(\"`Source.Name`\")).contains(\"AUSTRALIA\")) |\n",
                "    (F.col(\"`LINE OF BUSINESS`\").isNull()) |\n",
                "    (~F.upper(F.col(\"`LINE OF BUSINESS`\")).contains(\"ACCIDENT\"))\n",
                ")\n",
                "\n",
                "# --- Filter Employee Benefits (Alteryx Tool 84) — applies to ALL countries ---\n",
                "df = df.filter(\n",
                "    (F.col(\"`LINE OF BUSINESS`\").isNull()) |\n",
                "    (F.col(\"`LINE OF BUSINESS`\") != \"Employee Benefits\")\n",
                ")\n",
                "\n",
                "print(f\"After filters: {df.count()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# Cell 3: Date Formulas, Revenue Country, CCY, Branch Mapping, TRIM/UPPER\n",
                "# Alteryx: Formula tools per country (51,68,71,74,77,296)\n",
                "#          Date formulas (89,88,87,86,83,294)\n",
                "#          Branch mapping join (304) — HK only\n",
                "#          TRIM/UPPER + null handling (204)\n",
                "# =============================================================================\n",
                "\n",
                "# --- INVOICE DATE NEXT YEAR ---\n",
                "df = df.withColumn(\n",
                "    \"INVOICE DATE NEXT YEAR\",\n",
                "    F.when(F.col(\"`INVOICE DATE`\").isNull(), F.lit(None).cast(DateType()))\n",
                "     .otherwise(F.add_months(F.col(\"`INVOICE DATE`\"), 12))\n",
                ")\n",
                "\n",
                "# --- Replace null/empty EFFECTIVE DATE with INVOICE DATE ---\n",
                "df = df.withColumn(\n",
                "    \"EFFECTIVE DATE\",\n",
                "    F.coalesce(F.col(\"`EFFECTIVE DATE`\"), F.col(\"`INVOICE DATE`\"))\n",
                ")\n",
                "\n",
                "# --- Replace null/empty EXPIRY DATE with INVOICE DATE NEXT YEAR ---\n",
                "df = df.withColumn(\n",
                "    \"EXPIRY DATE\",\n",
                "    F.coalesce(F.col(\"`EXPIRY DATE`\"), F.col(\"`INVOICE DATE NEXT YEAR`\"))\n",
                ")\n",
                "\n",
                "# --- Revenue Country from Source.Name (M code lines 57-71) ---\n",
                "source_name = F.upper(F.col(\"`Source.Name`\"))\n",
                "df = df.withColumn(\n",
                "    \"Revenue Country\",\n",
                "    F.when(source_name.contains(\"CHINA\"), F.lit(\"China\"))\n",
                "     .when(source_name.contains(\"HONGKONG\"), F.lit(\"Hong Kong\"))\n",
                "     .when(source_name.contains(\"INDONESIA\"), F.lit(\"Indonesia\"))\n",
                "     .when(source_name.contains(\"TAIWAN\"), F.lit(\"Taiwan\"))\n",
                "     .when(source_name.contains(\"KOREA\"), F.lit(\"Korea\"))\n",
                "     .when(source_name.contains(\"PHILIPPINES\"), F.lit(\"Philippines\"))\n",
                "     .when(source_name.contains(\"AUSTRALIA\"), F.lit(\"Australia\"))\n",
                "     .when(source_name.contains(\"NEW ZEALAND\"), F.lit(\"New Zealand\"))\n",
                "     .otherwise(F.lit(None))\n",
                ")\n",
                "\n",
                "# --- FINAL DATE = INVOICE DATE ---\n",
                "df = df.withColumn(\"FINAL DATE\", F.col(\"`INVOICE DATE`\"))\n",
                "\n",
                "# --- FINAL YEAR ---\n",
                "df = df.withColumn(\n",
                "    \"FINAL YEAR\",\n",
                "    F.when(F.col(\"`FINAL DATE`\").isNull(), F.lit(None))\n",
                "     .otherwise(F.year(F.col(\"`FINAL DATE`\")).cast(StringType()))\n",
                ")\n",
                "\n",
                "# --- CCY from Revenue Country (M code lines 89-103) ---\n",
                "df = df.withColumn(\n",
                "    \"CCY\",\n",
                "    F.when(F.col(\"`Revenue Country`\") == \"China\", F.lit(\"CNY\"))\n",
                "     .when(F.col(\"`Revenue Country`\") == \"Hong Kong\", F.lit(\"HKD\"))\n",
                "     .when(F.col(\"`Revenue Country`\") == \"Indonesia\", F.lit(\"IDR\"))\n",
                "     .when(F.col(\"`Revenue Country`\") == \"Taiwan\", F.lit(\"TWD\"))\n",
                "     .when(F.col(\"`Revenue Country`\") == \"Korea\", F.lit(\"KRW\"))\n",
                "     .when(F.col(\"`Revenue Country`\") == \"Philippines\", F.lit(\"PHP\"))\n",
                "     .when(F.col(\"`Revenue Country`\") == \"Australia\", F.lit(\"AUD\"))\n",
                "     .when(F.col(\"`Revenue Country`\") == \"New Zealand\", F.lit(\"NZD\"))\n",
                "     .otherwise(F.lit(None))\n",
                ")\n",
                "\n",
                "# --- CCYYEAR ---\n",
                "df = df.withColumn(\n",
                "    \"CCYYEAR\",\n",
                "    F.when(\n",
                "        F.col(\"CCY\").isNull() | F.col(\"`FINAL YEAR`\").isNull(),\n",
                "        F.lit(None)\n",
                "    ).otherwise(F.concat(F.col(\"CCY\"), F.lit(\"-\"), F.col(\"`FINAL YEAR`\")))\n",
                ")\n",
                "\n",
                "# --- Branch Mapping Join — HK only (Alteryx Tool 304) ---\n",
                "# Replaces INSURER COUNTRY for HK rows using INS BRANCH → BRANCH lookup\n",
                "df_branch = spark.table(REF_BRANCH_MAPPING)\n",
                "df = df.join(\n",
                "    df_branch.select(\n",
                "        F.col(\"BRANCH\").alias(\"_branch_key\"),\n",
                "        F.col(\"`INSURER COUNTRY`\").alias(\"_branch_insurer_country\")\n",
                "    ),\n",
                "    F.col(\"`INS BRANCH`\") == F.col(\"_branch_key\"),\n",
                "    \"left\"\n",
                ")\n",
                "\n",
                "# For HK rows: use branch mapping INSURER COUNTRY; others: keep original\n",
                "df = df.withColumn(\n",
                "    \"INSURER COUNTRY\",\n",
                "    F.when(\n",
                "        F.col(\"`Revenue Country`\") == \"Hong Kong\",\n",
                "        F.coalesce(F.col(\"_branch_insurer_country\"), F.col(\"`INSURER COUNTRY`\"))\n",
                "    ).otherwise(F.col(\"`INSURER COUNTRY`\"))\n",
                ").drop(\"_branch_key\", \"_branch_insurer_country\")\n",
                "\n",
                "# --- TRIM + UPPER: RISK DESCRIPTION, INSURER NAME, CCYYEAR (Alteryx Tool 204) ---\n",
                "df = df.withColumn(\n",
                "    \"RISK DESCRIPTION\",\n",
                "    F.when(F.col(\"`RISK DESCRIPTION`\").isNull(), F.lit(None))\n",
                "     .otherwise(F.trim(F.upper(F.col(\"`RISK DESCRIPTION`\"))))\n",
                ")\n",
                "df = df.withColumn(\n",
                "    \"INSURER NAME\",\n",
                "    F.when(F.col(\"`INSURER NAME`\").isNull(), F.lit(None))\n",
                "     .otherwise(F.trim(F.upper(F.col(\"`INSURER NAME`\"))))\n",
                ")\n",
                "df = df.withColumn(\n",
                "    \"CCYYEAR\",\n",
                "    F.when(F.col(\"CCYYEAR\").isNull(), F.lit(None))\n",
                "     .otherwise(F.trim(F.upper(F.col(\"CCYYEAR\"))))\n",
                ")\n",
                "\n",
                "# --- Replace null RISK DESCRIPTION with \"Unknown\" ---\n",
                "df = df.withColumn(\n",
                "    \"RISK DESCRIPTION\",\n",
                "    F.when(F.col(\"`RISK DESCRIPTION`\").isNull(), F.lit(\"Unknown\"))\n",
                "     .otherwise(F.col(\"`RISK DESCRIPTION`\"))\n",
                ")\n",
                "\n",
                "print(f\"After transformations: {df.count()} rows\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Cell 4 — Reference Table Joins\n",
                "\n",
                "| Join | Left Key | Right Table | Right Key | Columns Brought In |\n",
                "|------|----------|-------------|-----------|--------------------|\n",
                "| Currency | `CCYYEAR` | `ref_Chloe_asia_currency_mapping` | `CCYYEAR` | `Value` → `CCYVALUE` |\n",
                "| Product | `RISK DESCRIPTION` | `ref_Chloe_eglobal_product_mapping` | `SYSTEM PRODUCT ID` | `Sub Product Class`, `GLOBs`, `GLOBS SPLIT P&C` |\n",
                "| Insurer | `INSURER NAME` | `ref_Chloe_insurer_mapping` | `Insurer` | `MAPPED_INSURER`, `Lloyd's Asia or Lloyd's London` |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# Cell 5: Reference Joins + Derived Columns + Final Select\n",
                "# Alteryx: Join (61) CCYYEAR, Join (198) Product, Join (199) Insurer,\n",
                "#          Formula (66), Select (195)\n",
                "# =============================================================================\n",
                "\n",
                "# --- 1. Currency mapping join on CCYYEAR (Alteryx Tool 61) ---\n",
                "df_ccy = spark.table(REF_CURRENCY_MAPPING).select(\n",
                "    F.trim(F.upper(F.col(\"CCYYEAR\"))).alias(\"_ccy_key\"),\n",
                "    F.col(\"Value\").alias(\"CCYVALUE\")\n",
                ")\n",
                "df = df.join(df_ccy, F.col(\"CCYYEAR\") == F.col(\"_ccy_key\"), \"left\").drop(\"_ccy_key\")\n",
                "\n",
                "# --- 2. Product mapping join on RISK DESCRIPTION (Alteryx Tool 198) ---\n",
                "df_product = spark.table(REF_PRODUCT_MAPPING).select(\n",
                "    F.trim(F.upper(F.col(\"`SYSTEM PRODUCT ID`\"))).alias(\"_prod_key\"),\n",
                "    F.col(\"`Sub Product Class`\"),\n",
                "    F.col(\"GLOBs\"),\n",
                "    F.col(\"`GLOBS SPLIT P&C`\")\n",
                ")\n",
                "df = df.join(df_product, F.col(\"`RISK DESCRIPTION`\") == F.col(\"_prod_key\"), \"left\").drop(\"_prod_key\")\n",
                "\n",
                "# --- 3. Insurer mapping join on INSURER NAME (Alteryx Tool 199) ---\n",
                "df_insurer = spark.table(REF_INSURER_MAPPING).select(\n",
                "    F.trim(F.upper(F.col(\"Insurer\"))).alias(\"_ins_key\"),\n",
                "    F.col(\"MAPPED_INSURER\"),\n",
                "    F.col(\"`Lloyd's Asia or Lloyd's London`\")\n",
                ")\n",
                "df = df.join(df_insurer, F.col(\"`INSURER NAME`\") == F.col(\"_ins_key\"), \"left\").drop(\"_ins_key\")\n",
                "\n",
                "# --- 4. Derived columns (Alteryx Tool 66) ---\n",
                "\n",
                "# PREMIUM (USD) = Premium * CCYVALUE  (null-safe, coalesce to 0)\n",
                "df = df.withColumn(\n",
                "    \"PREMIUM (USD)\",\n",
                "    F.coalesce(\n",
                "        F.col(\"Premium\").cast(DoubleType()) * F.col(\"CCYVALUE\").cast(DoubleType()),\n",
                "        F.lit(0.0)\n",
                "    )\n",
                ")\n",
                "\n",
                "# BROKERAGE (USD) = Brokerage * CCYVALUE  (null-safe, coalesce to 0)\n",
                "df = df.withColumn(\n",
                "    \"BROKERAGE (USD)\",\n",
                "    F.coalesce(\n",
                "        F.col(\"Brokerage\").cast(DoubleType()) * F.col(\"CCYVALUE\").cast(DoubleType()),\n",
                "        F.lit(0.0)\n",
                "    )\n",
                ")\n",
                "\n",
                "# SYSTEM ID = COMPANY + BRANCH + CLIENT NUMBER\n",
                "df = df.withColumn(\n",
                "    \"SYSTEM ID\",\n",
                "    F.when(\n",
                "        F.col(\"COMPANY\").isNull() | F.col(\"BRANCH\").isNull() | F.col(\"`CLIENT NUMBER`\").isNull(),\n",
                "        F.lit(None)\n",
                "    ).otherwise(\n",
                "        F.concat(F.col(\"COMPANY\"), F.col(\"BRANCH\"), F.col(\"`CLIENT NUMBER`\"))\n",
                "    )\n",
                ")\n",
                "\n",
                "# CLIENTID = if Party ID is null then SYSTEM ID else Party ID\n",
                "df = df.withColumn(\n",
                "    \"CLIENTID\",\n",
                "    F.coalesce(F.col(\"`Party ID`\"), F.col(\"`SYSTEM ID`\"))\n",
                ")\n",
                "\n",
                "# BUSINESS TYPE = \"Unknown\"\n",
                "df = df.withColumn(\"BUSINESS TYPE\", F.lit(\"Unknown\"))\n",
                "\n",
                "# DATA SOURCE = \"EglobaL\" (confirmed by user)\n",
                "df = df.withColumn(\"DATA SOURCE\", F.lit(\"EglobaL\"))\n",
                "\n",
                "# REINSURANCE DESCRIPTION (M code logic — correct version)\n",
                "df = df.withColumn(\n",
                "    \"REINSURANCE DESCRIPTION\",\n",
                "    F.when(\n",
                "        F.col(\"`RISK DESCRIPTION`\").isNotNull() &\n",
                "        F.upper(F.col(\"`RISK DESCRIPTION`\")).contains(\"REINSURANCE\"),\n",
                "        F.concat(\n",
                "            F.lit(\"Reinsurance:Refer to Policy Description\"),\n",
                "            F.coalesce(F.col(\"`Policy Description`\"), F.lit(\"\"))\n",
                "        )\n",
                "    ).otherwise(F.lit(\"null\"))\n",
                ")\n",
                "\n",
                "# --- 5. Final Select: 28 columns with PascalCase aliases ---\n",
                "# Following other notebooks: only keep Lloyd's Asia or Lloyd's London (aliased Lloyds)\n",
                "# Numeric columns coalesced to 0 for null safety\n",
                "df_final = df.select(\n",
                "    F.col(\"`INVOICE NO`\").cast(StringType()).alias(\"InvoicePolicyNumber\"),\n",
                "    F.col(\"`POLICY DEPT`\").cast(StringType()).alias(\"Department\"),\n",
                "    F.col(\"`INSURER NAME`\").cast(StringType()).alias(\"InsurerName\"),\n",
                "    F.col(\"`INSURER COUNTRY`\").cast(StringType()).alias(\"InsurerCountry\"),\n",
                "    F.col(\"`CLIENT NAME`\").cast(StringType()).alias(\"ClientName\"),\n",
                "    F.col(\"`RISK DESCRIPTION`\").cast(StringType()).alias(\"SystemProductId\"),\n",
                "    F.col(\"`INVOICE DATE`\").cast(DateType()).alias(\"InvoiceDate\"),\n",
                "    F.col(\"`EFFECTIVE DATE`\").cast(DateType()).alias(\"InceptionDate\"),\n",
                "    F.col(\"`EXPIRY DATE`\").cast(DateType()).alias(\"ExpiryDate\"),\n",
                "    F.col(\"`ACCOUNT HANDLER`\").cast(StringType()).alias(\"AccountHandler\"),\n",
                "    F.col(\"`Transaction Type`\").cast(StringType()).alias(\"TransactionType\"),\n",
                "    F.col(\"`Policy Description`\").cast(StringType()).alias(\"PolicyDescription\"),\n",
                "    F.col(\"`Party ID`\").cast(StringType()).alias(\"PartyIdWtw\"),\n",
                "    F.col(\"`DUNS Number`\").cast(StringType()).alias(\"DunsNumber\"),\n",
                "    F.col(\"`Revenue Country`\").cast(StringType()).alias(\"RevenueCountry\"),\n",
                "    F.col(\"`FINAL DATE`\").cast(DateType()).alias(\"FinalDate\"),\n",
                "    F.col(\"`Sub Product Class`\").cast(StringType()).alias(\"SubProductClass\"),\n",
                "    F.col(\"GLOBs\").cast(StringType()).alias(\"Globs\"),\n",
                "    F.col(\"`GLOBS SPLIT P&C`\").cast(StringType()).alias(\"GlobsSplitPc\"),\n",
                "    F.col(\"MAPPED_INSURER\").cast(StringType()).alias(\"InsurerMapping\"),\n",
                "    F.col(\"`Lloyd's Asia or Lloyd's London`\").cast(StringType()).alias(\"Lloyds\"),\n",
                "    F.coalesce(F.col(\"`PREMIUM (USD)`\"), F.lit(0.0)).cast(DoubleType()).alias(\"PremiumUsd\"),\n",
                "    F.coalesce(F.col(\"`BROKERAGE (USD)`\"), F.lit(0.0)).cast(DoubleType()).alias(\"BrokerageUsd\"),\n",
                "    F.col(\"`SYSTEM ID`\").cast(StringType()).alias(\"SystemId\"),\n",
                "    F.col(\"CLIENTID\").cast(StringType()).alias(\"ClientIdWtw\"),\n",
                "    F.col(\"`BUSINESS TYPE`\").cast(StringType()).alias(\"BusinessType\"),\n",
                "    F.col(\"`DATA SOURCE`\").cast(StringType()).alias(\"DataSource\"),\n",
                "    F.col(\"`REINSURANCE DESCRIPTION`\").cast(StringType()).alias(\"ReinsuranceDescription\")\n",
                ")\n",
                "\n",
                "print(f\"Final columns: {len(df_final.columns)}\")\n",
                "df_final.printSchema()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# Cell 6: Write to Silver\n",
                "# =============================================================================\n",
                "\n",
                "# --- Standardize column order across all silver notebooks ---\n",
                "STANDARD_COLUMNS = [\n",
                "    \"AccountHandler\", \"BrokerageUsd\", \"BusinessType\", \"ClientIdWtw\", \"ClientName\",\n",
                "    \"DataSource\", \"Department\", \"DunsNumber\", \"ExpiryDate\", \"FinalDate\",\n",
                "    \"Globs\", \"GlobsSplitPc\", \"InceptionDate\", \"InsurerCountry\", \"InsurerMapping\",\n",
                "    \"InsurerName\", \"InvoiceDate\", \"InvoicePolicyNumber\", \"Lloyds\", \"PartyIdWtw\",\n",
                "    \"PolicyDescription\", \"PremiumUsd\", \"ReinsuranceDescription\", \"RevenueCountry\",\n",
                "    \"SubProductClass\", \"SystemId\", \"SystemProductId\", \"TransactionType\"\n",
                "]\n",
                "df_final = df_final.select(*STANDARD_COLUMNS)\n",
                "\n",
                "print(f\"Writing to {TARGET_TABLE}...\")\n",
                "df_final.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(TARGET_TABLE)\n",
                "\n",
                "print(f\"Success. Rows written: {spark.table(TARGET_TABLE).count()}\")\n",
                "print(f\"Columns: {len(spark.table(TARGET_TABLE).columns)}\")\n",
                "display(spark.table(TARGET_TABLE).limit(5))"
            ]
        }
    ],
    "metadata": {
        "kernel_info": {
            "name": "synapse_pyspark"
        },
        "kernelspec": {
            "display_name": "Synapse PySpark",
            "language": "Python",
            "name": "synapse_pyspark"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        },
        "microsoft": {
            "language": "python",
            "ms_spell_check": {
                "ms_spell_check_language": "en"
            }
        },
        "notebook_environment": {},
        "nteract": {
            "version": "nteract-front-end@1.0.0"
        },
        "save_output": true,
        "spark_compute": {
            "compute_id": "/trident/default"
        },
        "synapse_widget": {
            "state": {},
            "version": "0.1"
        },
        "trident": {
            "lakehouse": {}
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}